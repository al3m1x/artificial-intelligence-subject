**ARTIFICIAL INTELLIGENCE LABORATORIES**

**SI1** ->
This lab focuses on linear regression, a fundamental supervised learning technique used by prediction of a continuous outcome based on input features. The task involves implementing both the closed-form solution and batch gradient descent to estimate the relationship between car weight and fuel efficiency (MPG). Performance is evaluated using mean squared error (MSE), and data standardization is applied to improve training stability.

**SI2** ->
This task implements a genetic algorithm to solve the knapsack problem, an NP-hard optimization problem. The algorithm follows the standard GA workflow, including population initialization, selection (roulette wheel), crossover, mutation, and population update to find an optimal or near-optimal solution.

**SI3** ->
This task involves implementing the Min-Max algorithm, a fundamental decision-making algorithm used in two-player zero-sum games like tic-tac-toe, chess, or connect4 (as in this example). The implementation includes recursive game tree exploration, a heuristic evaluation function, and an optimization using alpha-beta pruning to improve efficiency by reducing unnecessary calculations.

**SI4** ->
This task focuses on classification problems, including decision trees and random forests. The designed code trains and evaluates models on the Titanic dataset to analyze their performance.

**SI5** ->
This task explores clustering using the K-means algorithm, applied to the Iris dataset. The code implements different initialization methods, evaluates cluster quality, and visualizes the results.

**SI6** ->
This lab focuses on artificial neural networks, introducing the basic architecture and training methods. It includes tasks such as building a single neuron and a simple two-layer network, applying activation functions like ReLU and hardlim, and visualizing decision boundaries. The lab demonstrates the core principles behind neural network architecture, from individual neurons to multi-layer perceptrons (MLPs), as well as the training process using backpropagation and gradient descent methods.

**SI7** ->
This task involves implementing and training a reinforcement learning agent using the Q-learning algorithm in the FrozenLake environment, with the option for manual control or automatic training. The agent learns through interaction with the environment, adjusting its strategy to maximize rewards over time.
